{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/CARS/tabular_data.csv', index_col=0)"
      ],
      "metadata": {
        "id": "t6I7R6-mAPTR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Python code to preprocess every column of a DataFrame by replacing NaNs with the mean of the column\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "# Assuming 'df' is your DataFrame\n",
        "# df = pd.read_csv('your_data.csv')  # Example to load a DataFrame\n",
        "\n",
        "# Create an imputer object with a mean filling strategy\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Apply the imputer to our data frame\n",
        "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)"
      ],
      "metadata": {
        "id": "o9X2zPq3AVIy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabular_data = df_imputed"
      ],
      "metadata": {
        "id": "87CMBdm8AZST"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "z2UzBZEHAI8n"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, brier_score_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "graph_data = pd.read_csv('/content/drive/MyDrive/CARS/tensor.csv')\n",
        "X_graph = graph_data.iloc[:, :-1].values\n",
        "y_graph = graph_data['trojan'].values\n",
        "\n",
        "\n",
        "#tabular_data = pd.read_csv('actual_table_22_16features.csv')\n",
        "X_tabular = tabular_data.iloc[:, :-1].values\n",
        "y_tabular = tabular_data['trojan'].values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_tabular)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwYXkM_OAu2h",
        "outputId": "62f25d9d-81e1-427d-e517-9d0897a26573"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9800"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_graph = np.expand_dims(X_graph, axis=2)\n",
        "\n",
        "X_graph_train, X_graph_test, y_graph_train, y_graph_test = train_test_split(X_graph, y_graph, test_size=0.2, random_state=42)\n",
        "X_tabular_train, X_tabular_test, y_tabular_train, y_tabular_test = train_test_split(X_tabular, y_tabular, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "7f5o9ZY7DQdT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_convolutional_layers(input_tensor):\n",
        "    conv1 = tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu')(input_tensor)\n",
        "    pool1 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv1)\n",
        "    return pool1\n",
        "\n",
        "def create_dense_layers(input_tensor):\n",
        "    dense1 = tf.keras.layers.Dense(64, activation='relu')(input_tensor)\n",
        "    return dense1\n",
        "\n",
        "graph_input = tf.keras.layers.Input(shape=(X_graph.shape[1], X_graph.shape[2]))\n",
        "graph_conv_layers = create_convolutional_layers(graph_input)\n",
        "\n",
        "graph_flat = tf.keras.layers.Flatten()(graph_conv_layers)\n",
        "\n",
        "tabular_input = tf.keras.layers.Input(shape=(X_tabular.shape[1],))\n",
        "tabular_dense_layers = create_dense_layers(tabular_input)\n",
        "\n",
        "concatenated = tf.keras.layers.concatenate([graph_flat, tabular_dense_layers])\n",
        "\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(concatenated)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "output = tf.keras.layers.Dense(3, activation='softmax')(x)  # 'num_classes' is the number of classes in your multi-class problem\n",
        "\n",
        "model = tf.keras.models.Model(inputs=[graph_input, tabular_input], outputs=output)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "xrBhnNWmDrTM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Assuming 'y_graph_train' contains class labels (e.g., 0, 1, 2, ...) for multi-class classification\n",
        "y_graph_train_encoded = to_categorical(y_graph_train, num_classes=3)\n",
        "\n",
        "model.fit([X_graph_train, X_tabular_train], y_graph_train_encoded, epochs=20, batch_size=5, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKG1lt-gDtT7",
        "outputId": "6844b6d6-712b-44fa-ebaf-d62cc47f61b4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1568/1568 [==============================] - 10s 5ms/step - loss: 846732535529472.0000 - accuracy: 0.8481\n",
            "Epoch 2/20\n",
            "1568/1568 [==============================] - 8s 5ms/step - loss: 187886338048.0000 - accuracy: 0.8819\n",
            "Epoch 3/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 0.4551 - accuracy: 0.8825\n",
            "Epoch 4/20\n",
            "1568/1568 [==============================] - 6s 4ms/step - loss: 0.4429 - accuracy: 0.8827\n",
            "Epoch 5/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 0.5145 - accuracy: 0.8821\n",
            "Epoch 6/20\n",
            "1568/1568 [==============================] - 4s 2ms/step - loss: 0.4428 - accuracy: 0.8827\n",
            "Epoch 7/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 0.4692 - accuracy: 0.8825\n",
            "Epoch 8/20\n",
            "1568/1568 [==============================] - 6s 4ms/step - loss: 0.4435 - accuracy: 0.8825\n",
            "Epoch 9/20\n",
            "1568/1568 [==============================] - 4s 2ms/step - loss: 0.4428 - accuracy: 0.8827\n",
            "Epoch 10/20\n",
            "1568/1568 [==============================] - 4s 2ms/step - loss: 0.4428 - accuracy: 0.8827\n",
            "Epoch 11/20\n",
            "1568/1568 [==============================] - 6s 4ms/step - loss: 1657770213376.0000 - accuracy: 0.8797\n",
            "Epoch 12/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 0.4428 - accuracy: 0.8827\n",
            "Epoch 13/20\n",
            "1568/1568 [==============================] - 4s 2ms/step - loss: 0.5392 - accuracy: 0.8827\n",
            "Epoch 14/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 0.4428 - accuracy: 0.8827\n",
            "Epoch 15/20\n",
            "1568/1568 [==============================] - 6s 4ms/step - loss: 0.4428 - accuracy: 0.8827\n",
            "Epoch 16/20\n",
            "1568/1568 [==============================] - 4s 2ms/step - loss: 0.4429 - accuracy: 0.8827\n",
            "Epoch 17/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 4435441152.0000 - accuracy: 0.8825\n",
            "Epoch 18/20\n",
            "1568/1568 [==============================] - 7s 4ms/step - loss: 0.4501 - accuracy: 0.8824\n",
            "Epoch 19/20\n",
            "1568/1568 [==============================] - 6s 4ms/step - loss: 0.5251 - accuracy: 0.8823\n",
            "Epoch 20/20\n",
            "1568/1568 [==============================] - 4s 2ms/step - loss: 0.5422 - accuracy: 0.8825\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x790529161780>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict([X_graph_test, X_tabular_test])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the predicted class indices\n",
        "\n",
        "# Calculate accuracy and other metrics for multi-class classification\n",
        "accuracy = accuracy_score(y_graph_test, y_pred_classes)\n",
        "confusion = confusion_matrix(y_graph_test, y_pred_classes)\n",
        "classification_rep = classification_report(y_graph_test, y_pred_classes)\n",
        "\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "print(f'Confusion Matrix:\\n{confusion}')\n",
        "print(f'Classification Report:\\n{classification_rep}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7m8MFVcD1c9",
        "outputId": "49377dd9-9bef-4c4e-e1a4-8478f88df2e8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62/62 [==============================] - 0s 2ms/step\n",
            "Accuracy: 88.06%\n",
            "Confusion Matrix:\n",
            "[[1726    0    0]\n",
            " [ 132    0    0]\n",
            " [ 102    0    0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94      1726\n",
            "           1       0.00      0.00      0.00       132\n",
            "           2       0.00      0.00      0.00       102\n",
            "\n",
            "    accuracy                           0.88      1960\n",
            "   macro avg       0.29      0.33      0.31      1960\n",
            "weighted avg       0.78      0.88      0.82      1960\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import brier_score_loss\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Assuming 'y_graph_test' contains class labels (e.g., 0, 1, 2, ...) for multi-class classification\n",
        "# Calculate the true class probabilities as one-hot encoded labels\n",
        "y_true_one_hot = to_categorical(y_graph_test, num_classes=3)\n",
        "\n",
        "# Predict class probabilities using your trained model\n",
        "y_pred_probabilities = model.predict([X_graph_test, X_tabular_test])\n",
        "\n",
        "# Calculate the Brier score for each class\n",
        "brier_scores = []\n",
        "\n",
        "for class_idx in range(3):  # Assuming you have 3 classes\n",
        "    class_true_probs = y_true_one_hot[:, class_idx]\n",
        "    class_pred_probs = y_pred_probabilities[:, class_idx]\n",
        "    class_brier_score = brier_score_loss(class_true_probs, class_pred_probs)\n",
        "    brier_scores.append(class_brier_score)\n",
        "\n",
        "print(f'Brier Scores for Each Class:')\n",
        "for class_idx, score in enumerate(brier_scores):\n",
        "    print(f'Class {class_idx}: {score:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqFOScVdEbY-",
        "outputId": "6b0f8751-7604-4f23-90ba-a8c96911e418"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62/62 [==============================] - 0s 4ms/step\n",
            "Brier Scores for Each Class:\n",
            "Class 0: 0.1052\n",
            "Class 1: 0.0628\n",
            "Class 2: 0.0494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NVtqpeZuEmir"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}