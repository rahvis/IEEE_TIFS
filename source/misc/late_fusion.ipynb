{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/CARS/tabular_data.csv', index_col=0)"
      ],
      "metadata": {
        "id": "_SA3omazF6eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Python code to preprocess every column of a DataFrame by replacing NaNs with the mean of the column\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "# Assuming 'df' is your DataFrame\n",
        "# df = pd.read_csv('your_data.csv')  # Example to load a DataFrame\n",
        "\n",
        "# Create an imputer object with a mean filling strategy\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Apply the imputer to our data frame\n",
        "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)"
      ],
      "metadata": {
        "id": "jvy9iIbUF8dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabular_data = df_imputed"
      ],
      "metadata": {
        "id": "L3ta_sAoF_nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLJjEttHC1bO",
        "outputId": "ebb60305-8819-4083-c8d7-b66baa2178b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1568/1568 [==============================] - 11s 7ms/step - loss: 3.6517 - accuracy: 0.8649\n",
            "Epoch 2/20\n",
            "1568/1568 [==============================] - 9s 5ms/step - loss: 0.4797 - accuracy: 0.8821\n",
            "Epoch 3/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 0.4456 - accuracy: 0.8827\n",
            "Epoch 4/20\n",
            "1568/1568 [==============================] - 6s 4ms/step - loss: 0.4474 - accuracy: 0.8825\n",
            "Epoch 5/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 0.4504 - accuracy: 0.8824\n",
            "Epoch 6/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 0.4429 - accuracy: 0.8827\n",
            "Epoch 7/20\n",
            "1568/1568 [==============================] - 5s 3ms/step - loss: 0.4424 - accuracy: 0.8827\n",
            "Epoch 8/20\n",
            "1568/1568 [==============================] - 5s 3ms/step - loss: 0.4533 - accuracy: 0.8820\n",
            "Epoch 9/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 0.4454 - accuracy: 0.8827\n",
            "Epoch 10/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 0.4431 - accuracy: 0.8827\n",
            "Epoch 11/20\n",
            "1568/1568 [==============================] - 6s 4ms/step - loss: 0.4432 - accuracy: 0.8827\n",
            "Epoch 12/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 0.4427 - accuracy: 0.8827\n",
            "Epoch 13/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 0.4891 - accuracy: 0.8824\n",
            "Epoch 14/20\n",
            "1568/1568 [==============================] - 6s 4ms/step - loss: 0.7688 - accuracy: 0.8827\n",
            "Epoch 15/20\n",
            "1568/1568 [==============================] - 5s 3ms/step - loss: 0.4427 - accuracy: 0.8827\n",
            "Epoch 16/20\n",
            "1568/1568 [==============================] - 4s 2ms/step - loss: 0.4469 - accuracy: 0.8827\n",
            "Epoch 17/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 0.4426 - accuracy: 0.8827\n",
            "Epoch 18/20\n",
            "1568/1568 [==============================] - 6s 4ms/step - loss: 0.4443 - accuracy: 0.8827\n",
            "Epoch 19/20\n",
            "1568/1568 [==============================] - 5s 3ms/step - loss: 0.4470 - accuracy: 0.8827\n",
            "Epoch 20/20\n",
            "1568/1568 [==============================] - 5s 3ms/step - loss: 0.4430 - accuracy: 0.8827\n",
            "Epoch 1/20\n",
            "1568/1568 [==============================] - 7s 4ms/step - loss: 2283602972770304.0000 - accuracy: 0.8375\n",
            "Epoch 2/20\n",
            "1568/1568 [==============================] - 4s 2ms/step - loss: 32845406208.0000 - accuracy: 0.8819\n",
            "Epoch 3/20\n",
            "1568/1568 [==============================] - 3s 2ms/step - loss: 0.4729 - accuracy: 0.8823\n",
            "Epoch 4/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 0.4896 - accuracy: 0.8821\n",
            "Epoch 5/20\n",
            "1568/1568 [==============================] - 5s 3ms/step - loss: 0.4658 - accuracy: 0.8824\n",
            "Epoch 6/20\n",
            "1568/1568 [==============================] - 4s 2ms/step - loss: 0.4814 - accuracy: 0.8824\n",
            "Epoch 7/20\n",
            "1568/1568 [==============================] - 3s 2ms/step - loss: 1856525303808.0000 - accuracy: 0.8806\n",
            "Epoch 8/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 0.4539 - accuracy: 0.8828\n",
            "Epoch 9/20\n",
            "1568/1568 [==============================] - 5s 3ms/step - loss: 0.4460 - accuracy: 0.8828\n",
            "Epoch 10/20\n",
            "1568/1568 [==============================] - 3s 2ms/step - loss: 0.4539 - accuracy: 0.8825\n",
            "Epoch 11/20\n",
            "1568/1568 [==============================] - 3s 2ms/step - loss: 0.4444 - accuracy: 0.8827\n",
            "Epoch 12/20\n",
            "1568/1568 [==============================] - 4s 2ms/step - loss: 0.4418 - accuracy: 0.8828\n",
            "Epoch 13/20\n",
            "1568/1568 [==============================] - 5s 3ms/step - loss: 0.4416 - accuracy: 0.8828\n",
            "Epoch 14/20\n",
            "1568/1568 [==============================] - 3s 2ms/step - loss: 0.4497 - accuracy: 0.8825\n",
            "Epoch 15/20\n",
            "1568/1568 [==============================] - 4s 2ms/step - loss: 0.4423 - accuracy: 0.8825\n",
            "Epoch 16/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 0.4444 - accuracy: 0.8824\n",
            "Epoch 17/20\n",
            "1568/1568 [==============================] - 6s 4ms/step - loss: 1752585863168.0000 - accuracy: 0.8821\n",
            "Epoch 18/20\n",
            "1568/1568 [==============================] - 6s 4ms/step - loss: 0.4415 - accuracy: 0.8828\n",
            "Epoch 19/20\n",
            "1568/1568 [==============================] - 4s 2ms/step - loss: 0.4451 - accuracy: 0.8825\n",
            "Epoch 20/20\n",
            "1568/1568 [==============================] - 4s 3ms/step - loss: 0.4444 - accuracy: 0.8829\n",
            "62/62 [==============================] - 0s 3ms/step\n",
            "62/62 [==============================] - 0s 2ms/step\n",
            "Accuracy: 88.06%\n",
            "Confusion Matrix:\n",
            "[[1726    0    0]\n",
            " [ 132    0    0]\n",
            " [ 102    0    0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94      1726\n",
            "           1       0.00      0.00      0.00       132\n",
            "           2       0.00      0.00      0.00       102\n",
            "\n",
            "    accuracy                           0.88      1960\n",
            "   macro avg       0.29      0.33      0.31      1960\n",
            "weighted avg       0.78      0.88      0.82      1960\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, brier_score_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load your data (replace 'actual_graph_22_16features.csv' and 'actual_table_22_16features.csv' with your actual data file paths)\n",
        "graph_data = pd.read_csv('/content/drive/MyDrive/CARS/tensor.csv')\n",
        "#tabular_data = pd.read_csv('actual_table_22_16features.csv')\n",
        "\n",
        "X_graph = graph_data.iloc[:, :-1].values\n",
        "y_graph = graph_data['trojan'].values\n",
        "\n",
        "X_tabular = tabular_data.iloc[:, :-1].values\n",
        "y_tabular = tabular_data['trojan'].values\n",
        "\n",
        "# Reshape X_graph to have 3 dimensions (batch size, sequence length, input dimension)\n",
        "X_graph = X_graph.reshape(X_graph.shape[0], X_graph.shape[1], 1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_graph_train, X_graph_test, y_graph_train, y_graph_test = train_test_split(X_graph, y_graph, test_size=0.2, random_state=42)\n",
        "X_tabular_train, X_tabular_test, y_tabular_train, y_tabular_test = train_test_split(X_tabular, y_tabular, test_size=0.2, random_state=42)\n",
        "\n",
        "# Modify your create_graph_model and create_tabular_model functions for multi-class classification\n",
        "def create_graph_model(input_shape, num_classes):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')  # 'num_classes' is the number of classes in your multi-class problem\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_tabular_model(input_shape, num_classes):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')  # 'num_classes' is the number of classes in your multi-class problem\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Assuming you have 'num_classes' classes in your multi-class problem\n",
        "num_classes = 3  # Replace with the actual number of classes in your dataset\n",
        "\n",
        "# Train your graph model and tabular model (replace with your actual training code)\n",
        "\n",
        "graph_model = create_graph_model(X_graph_train.shape[1:], num_classes)\n",
        "graph_model.fit(X_graph_train, to_categorical(y_graph_train, num_classes=num_classes), epochs=20, batch_size=5, verbose=1)\n",
        "\n",
        "tabular_model = create_tabular_model(X_tabular_train.shape[1:], num_classes)\n",
        "tabular_model.fit(X_tabular_train, to_categorical(y_tabular_train, num_classes=num_classes), epochs=20, batch_size=5, verbose=1)\n",
        "\n",
        "# Predictions from both models\n",
        "graph_predictions = graph_model.predict(X_graph_test)\n",
        "tabular_predictions = tabular_model.predict(X_tabular_test)\n",
        "\n",
        "# Combine predictions using averaging (you can adjust this method as needed)\n",
        "combined_predictions = (graph_predictions + tabular_predictions) / 2\n",
        "\n",
        "# Convert combined predictions to class labels by selecting the class with the highest probability\n",
        "combined_predictions_classes = np.argmax(combined_predictions, axis=1)\n",
        "\n",
        "# Calculate accuracy, confusion matrix, classification report, and Brier score for multi-class classification\n",
        "accuracy = accuracy_score(y_graph_test, combined_predictions_classes)\n",
        "confusion = confusion_matrix(y_graph_test, combined_predictions_classes)\n",
        "classification_rep = classification_report(y_graph_test, combined_predictions_classes)\n",
        "\n",
        "# Calculate the Brier score\n",
        "y_true_one_hot = to_categorical(y_graph_test, num_classes=num_classes)\n",
        "\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "print(f'Confusion Matrix:\\n{confusion}')\n",
        "print(f'Classification Report:\\n{classification_rep}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions from the model\n",
        "graph_predictions = graph_model.predict(X_graph_test)\n",
        "\n",
        "# Convert predictions to class labels by selecting the class with the highest probability\n",
        "graph_predictions_classes = np.argmax(graph_predictions, axis=1)\n",
        "\n",
        "# Calculate accuracy, confusion matrix, classification report, and Brier score for multi-class classification\n",
        "accuracy = accuracy_score(y_graph_test, graph_predictions_classes)\n",
        "confusion = confusion_matrix(y_graph_test, graph_predictions_classes)\n",
        "classification_rep = classification_report(y_graph_test, graph_predictions_classes)\n",
        "\n",
        "\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "print(f'Confusion Matrix:\\n{confusion}')\n",
        "print(f'Classification Report:\\n{classification_rep}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kpQ3Y-IGHf2",
        "outputId": "c7044716-7be1-4404-962f-8dddbb4bbe92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62/62 [==============================] - 0s 3ms/step\n",
            "Accuracy: 88.06%\n",
            "Confusion Matrix:\n",
            "[[1726    0    0]\n",
            " [ 132    0    0]\n",
            " [ 102    0    0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94      1726\n",
            "           1       0.00      0.00      0.00       132\n",
            "           2       0.00      0.00      0.00       102\n",
            "\n",
            "    accuracy                           0.88      1960\n",
            "   macro avg       0.29      0.33      0.31      1960\n",
            "weighted avg       0.78      0.88      0.82      1960\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import brier_score_loss\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Assuming 'y_graph_test' contains class labels (e.g., 0, 1, 2, ...) for multi-class classification\n",
        "# Calculate the true class probabilities as one-hot encoded labels\n",
        "y_true_one_hot = to_categorical(y_graph_test, num_classes=3)\n",
        "\n",
        "# Predict class probabilities using your trained model\n",
        "y_pred_probabilities = graph_model.predict(X_graph_test)\n",
        "\n",
        "# Calculate the Brier score for each class\n",
        "brier_scores = []\n",
        "\n",
        "for class_idx in range(3):  # Assuming you have 3 classes\n",
        "    class_true_probs = y_true_one_hot[:, class_idx]\n",
        "    class_pred_probs = y_pred_probabilities[:, class_idx]\n",
        "    class_brier_score = brier_score_loss(class_true_probs, class_pred_probs)\n",
        "    brier_scores.append(class_brier_score)\n",
        "\n",
        "print(f'Brier Scores for Each Class:')\n",
        "for class_idx, score in enumerate(brier_scores):\n",
        "    print(f'Class {class_idx}: {score:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4hVe-7-H7Mr",
        "outputId": "3e9dc015-66a3-423b-81ed-6026c62e5857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62/62 [==============================] - 0s 3ms/step\n",
            "Brier Scores for Each Class:\n",
            "Class 0: 0.1052\n",
            "Class 1: 0.0629\n",
            "Class 2: 0.0493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FiK10UqlKNLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yuEJ8y-TLSBv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}